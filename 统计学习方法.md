# 统计学习方法概论

## 统计学习

## 监督学习

## 统计学习三要素

## 模型评估和模型选择

## 正则化与交叉验证

### 正则化

- L1范数：得到稀疏的权值？。e.g. LASSO
- L2范数：得到平滑的权值？。e.g. Ridge Regression

### 交叉验证

## 泛化能力

Error = bias + variance + noise

![image](http://images.cnitblog.com/blog/663864/201411/081949392689088.png)

模型搞得复杂，参数多，才能低偏差，模型简单，参数少，才能低方差，

http://www.cnblogs.com/jianxinzhou/p/4083921.html

## 生成模型与判别模型

### 生成模型

- 生成模型 ： 数据-> P(X,Y) ->P(Y|X)
- 常见的生成模型：朴素贝叶斯和HMM，混合高斯模型

### 判别模型

- 数据 -> P(Y|X)
- 常见的判别模型：KNN，感知机,CRF,逻辑回归，SVM，最大熵模型

## 分类问题

### 二类分类问题的常见评价指标

- 准确率（accuracy）
- 精确率（precision）
- 召回率（recall）：
- F1值：是准确率与召回率的调和均值

## 标注问题

## 回归问题



# 感知机

# KNN

# 朴素贝叶斯

# 决策树

## What

## Why

(例子来源：李航统计学习方法）

| ID   | 年龄   | 有工作  | 有自己的房子 | 信贷情况 | 类别   |
| ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 青年   | 否    | 否      | 一般   | 否    |
| 2    | 青年   | 否    | 否      | 好    | 否    |
| 3    | 中年   | 否    | 否      | 一般   | 否    |



## How

# 逻辑回归与最大熵模型

# 支持向量机(SVM)

### SVM 核函数

- 多项式核函数
- 高斯核函数
- 字符串核函数
- 径向基核函数
- sigmoid核函数
- 拉普拉斯核函数

# 提升方法

## 提升方法AdaBoost算法

## AdaBoost算法的误差分析

## AdaBoost的解释

## 提升树

## Boosting 与 Bagging（Bootstrap aggregation）

# EM算法

## What

EM算法是一种迭代算法。全称为最大期望算法（Expectation Maximization）。

## Why（统计学习方法）

假设有三枚硬币A、B、C，每个硬币正面出现的概率是π、p、q。进行如下的掷硬币实验：先掷硬币A，正面向上选B，反面选C；然后掷选择的硬币，正面记1，反面记0。独立的进行10次实验，结果如下：1，1，0，1，0，0，1，0，1，1。假设只能观察最终的结果(0 or 1)，而不能观测掷硬币的过程(不知道选的是B or C)，问如何估计三硬币的正面出现的概率？

## How



## EM算法在高斯混合模型中的应用

### 高斯混合分布模型



# 隐马尔可夫（HMM）

## 发展过程

- HMM - MEMM (最大熵马尔科夫模型) - CRF
## Why（wiki）

假设你有一个住得很远的朋友，他每天跟你打电话告诉你他那天做了什么。你的朋友仅仅对三种活动感兴趣：公园散步，购物以及清理房间。他选择做什么事情只凭天气。你对于他所住的地方的天气情况并不了解，但是你知道总的趋势。在他告诉你每天所做的事情基础上，你想要猜测他所在地的天气情况。

你认为天气的运行就像一个[马尔可夫链](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)。其有两个状态"雨"和"晴"，但是你无法直接观察它们，也就是说，它们对于你是隐藏的。每天，你的朋友有一定的概率进行下列活动："散步", "购物"，或"清理".因为你朋友告诉你他的活动，所以这些活动就是你的观察数据。这整个系统就是一个隐马尔可夫模型HMM.

你知道这个地区的总的天气趋势（今天下雨明天下雨的概率，今天下雨明天晴天的概率），并且平时知道你朋友会做的事情。

注意：只有观测序列时而没有状态序列时是采用的EM算法。

## What ?

## How?

HMM 有三个典型(canonical)问题（wiki）

###　预测：

已知模型参数和某一特定的输出序列，求最后时刻各个隐含状态的概率分布，通常使用前向算法解决

### 平滑

已知模型参数和某一特定数序序列，求中间时刻的各个隐含状态的概率分布，通常使用前向后向算法。

### 解码

已知模型参数，寻找最可能产生某一特定输出序列的隐含状态的序列，通常使用维特比算法进行解决。[维特比算法的动态图](https://en.wikipedia.org/wiki/File:Viterbi_animated_demo.gif)

另外已知输出序列，寻找最可能的状态转移及输出概率，通常使用B-W算法以及反向维特比算法。

## 概率计算方法

### 直接计算法

### 前向算法

### 后向算法

### 一些概率值和期望值的计算

## 学习算法

### 监督学习算法

### Baum—Welch算法

### B-W算法的参数估计公式

## 预测算法

### 近似算法

### 维特比算法

# 条件随机场（CRF）

-----

# 非监督学习

# 时间序列分析

# 问题归类

##  常见的降维方法

- LASSO，聚类，PCA，小波分析，线性判别，拉普拉斯特征映射

# 梯度下降法

## [Why](http://blog.csdn.net/coder_oyang/article/details/46544089)

y = x^2 求出y的最小值

## What

求解无约束最优化的问题

## How

### python 实现

# 牛顿法和拟牛顿法

# 拉格朗日对偶性



# 半监督学习

## 主动学习



#推荐算法
## 内容的推荐算法
## 协同过滤推荐算法
## 基于知识的推荐算法